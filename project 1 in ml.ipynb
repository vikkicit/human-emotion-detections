{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91aaa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree and cnn with zernike features/ck+\n",
    "import os\n",
    "import zipfile\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import mahotas\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Concatenate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Extract dataset ---\n",
    "zip_path = \"C:\\\\Users\\\\yuvan\\\\OneDrive\\\\Desktop\\\\CK+48\"\n",
    "extract_dir = \"data\"\n",
    "if not os.path.exists(extract_dir):\n",
    "    print(\"Extracting dataset...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "else:\n",
    "    print(\"Dataset already exists, skipping extraction.\")\n",
    "\n",
    "def find_subfolder(base_dir, name='train'):\n",
    "    for root, dirs, _ in os.walk(base_dir):\n",
    "        if name in dirs:\n",
    "            return os.path.join(root, name)\n",
    "    raise FileNotFoundError(f\"'{name}' folder not found inside {base_dir}\")\n",
    "\n",
    "train_dir = find_subfolder(extract_dir, 'train')\n",
    "test_dir = find_subfolder(extract_dir, 'test')\n",
    "\n",
    "# --- Mediapipe FaceMesh ---\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)\n",
    "\n",
    "def get_face_crop(img):\n",
    "    h, w, _ = img.shape\n",
    "    results = face_mesh.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    if results.multi_face_landmarks:\n",
    "        x_coords = [lm.x for lm in results.multi_face_landmarks[0].landmark]\n",
    "        y_coords = [lm.y for lm in results.multi_face_landmarks[0].landmark]\n",
    "        x_min, x_max = int(min(x_coords) * w), int(max(x_coords) * w)\n",
    "        y_min, y_max = int(min(y_coords) * h), int(max(y_coords) * h)\n",
    "        x_min, x_max = max(0, x_min), min(w, x_max)\n",
    "        y_min, y_max = max(0, y_min), min(h, y_max)\n",
    "        face = img[y_min:y_max, x_min:x_max]\n",
    "        if face.size != 0:\n",
    "            return cv2.resize(face, (48, 48))\n",
    "    return None\n",
    "\n",
    "def extract_zernike(gray_img):\n",
    "    radius = 21\n",
    "    thresh = gray_img > gray_img.mean()\n",
    "    return mahotas.features.zernike_moments(thresh.astype(np.uint8), radius, degree=8)\n",
    "\n",
    "valid_labels = ['happy', 'sad', 'angry', 'fear', 'surprise']\n",
    "\n",
    "def load_images_with_zernike(folder):\n",
    "    X_img, X_zernike, y = [], [], []\n",
    "    for label in os.listdir(folder):\n",
    "        original_label = label\n",
    "        if label == 'neutral':\n",
    "            label = 'surprise'\n",
    "        if label not in valid_labels:\n",
    "            continue\n",
    "        label_path = os.path.join(folder, original_label)\n",
    "        for file in os.listdir(label_path):\n",
    "            img_path = os.path.join(label_path, file)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            face = get_face_crop(img)\n",
    "            if face is not None:\n",
    "                gray = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "                try:\n",
    "                    zernike_feat = extract_zernike(gray)\n",
    "                    X_img.append(gray)\n",
    "                    X_zernike.append(zernike_feat)\n",
    "                    y.append(label)\n",
    "                except:\n",
    "                    continue\n",
    "    return np.array(X_img), np.array(X_zernike), np.array(y)\n",
    "\n",
    "# --- Load dataset ---\n",
    "print(\"Loading training data...\")\n",
    "X_train_img, X_train_zernike, y_train = load_images_with_zernike(train_dir)\n",
    "print(\"Loading testing data...\")\n",
    "X_test_img, X_test_zernike, y_test = load_images_with_zernike(test_dir)\n",
    "\n",
    "# Normalize and reshape\n",
    "X_train_img = X_train_img.astype('float32') / 255.\n",
    "X_test_img = X_test_img.astype('float32') / 255.\n",
    "X_train_img = X_train_img[..., np.newaxis]\n",
    "X_test_img = X_test_img[..., np.newaxis]\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n",
    "y_train_cat = to_categorical(y_train_enc)\n",
    "y_test_cat = to_categorical(y_test_enc)\n",
    "\n",
    "# --- CNN + Zernike Model ---\n",
    "cnn_input = Input(shape=(48, 48, 1), name='cnn_input')\n",
    "x = Conv2D(32, (3, 3), activation='relu')(cnn_input)\n",
    "x = MaxPooling2D(2, 2)(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(2, 2)(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "zernike_input = Input(shape=(X_train_zernike.shape[1],), name='zernike_input')\n",
    "z = Dense(64, activation='relu')(zernike_input)\n",
    "\n",
    "combined = Concatenate()([x, z])\n",
    "combined = Dense(128, activation='relu')(combined)\n",
    "combined = Dropout(0.3)(combined)\n",
    "output = Dense(len(le.classes_), activation='softmax')(combined)\n",
    "\n",
    "model = Model(inputs=[cnn_input, zernike_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"Training CNN + Zernike model...\")\n",
    "model.fit([X_train_img, X_train_zernike], y_train_cat, epochs=20, batch_size=32,\n",
    "          validation_data=([X_test_img, X_test_zernike], y_test_cat))\n",
    "\n",
    "model.save(\"emotion_cnn_zernike_model.h5\")\n",
    "\n",
    "# Evaluate CNN+Zernike model\n",
    "y_pred = model.predict([X_test_img, X_test_zernike])\n",
    "y_pred_cls = np.argmax(y_pred, axis=1)\n",
    "cnn_accuracy = accuracy_score(y_test_enc, y_pred_cls)\n",
    "cnn_error_rate = 1 - cnn_accuracy\n",
    "print(f\"CNN + Zernike Test Accuracy: {cnn_accuracy * 100:.2f}%\")\n",
    "print(f\"CNN + Zernike Error Rate: {cnn_error_rate * 100:.2f}%\")\n",
    "\n",
    "# --- Train and evaluate Decision Tree on Zernike features only ---\n",
    "print(\"\\nTraining Decision Tree on Zernike features...\")\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train_zernike, y_train_enc)\n",
    "\n",
    "y_dt_pred = dt.predict(X_test_zernike)\n",
    "dt_accuracy = accuracy_score(y_test_enc, y_dt_pred)\n",
    "dt_error_rate = 1 - dt_accuracy\n",
    "print(f\"Decision Tree Accuracy: {dt_accuracy * 100:.2f}%\")\n",
    "print(f\"Decision Tree Error Rate: {dt_error_rate * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nClassification Report (Decision Tree):\")\n",
    "print(classification_report(y_test_enc, y_dt_pred, target_names=le.classes_))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_enc, y_dt_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title(\"Decision Tree Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# --- Real-time Detection (CNN + Zernike only) ---\n",
    "print(\"Starting real-time detection. Press 'q' to quit.\")\n",
    "model = load_model(\"emotion_cnn_zernike_model.h5\")\n",
    "emotion_labels = le.classes_\n",
    "face_mesh_live = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, refine_landmarks=True)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "predicted_emotions = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    h, w, _ = frame.shape\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh_live.process(rgb)\n",
    "    if results.multi_face_landmarks:\n",
    "        landmarks = results.multi_face_landmarks[0].landmark\n",
    "        x_all = [lm.x for lm in landmarks]\n",
    "        y_all = [lm.y for lm in landmarks]\n",
    "        x_min, x_max = int(min(x_all) * w), int(max(x_all) * w)\n",
    "        y_min, y_max = int(min(y_all) * h), int(max(y_all) * h)\n",
    "        x_min, x_max = max(0, x_min), min(w, x_max)\n",
    "        y_min, y_max = max(0, y_min), min(h, y_max)\n",
    "\n",
    "        face_crop = frame[y_min:y_max, x_min:x_max]\n",
    "        if face_crop.size > 0:\n",
    "            gray = cv2.cvtColor(face_crop, cv2.COLOR_BGR2GRAY)\n",
    "            resized = cv2.resize(gray, (48, 48))\n",
    "            norm = resized.astype('float32') / 255.\n",
    "            zernike_feat = extract_zernike(resized)\n",
    "            input_img = np.expand_dims(norm, axis=(0, -1))\n",
    "            input_zernike = np.expand_dims(zernike_feat, axis=0)\n",
    "            pred = model.predict([input_img, input_zernike], verbose=0)\n",
    "            emotion = emotion_labels[np.argmax(pred)]\n",
    "            predicted_emotions.append(emotion)\n",
    "            cv2.putText(frame, f'Emotion: {emotion}', (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "    cv2.imshow(\"Emotion Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# --- Plot Real-Time Emotion Frequency ---\n",
    "if predicted_emotions:\n",
    "    counts = Counter(predicted_emotions)\n",
    "    plt.bar(counts.keys(), counts.values(), color='orange')\n",
    "    plt.title(\"Real-Time Emotion Frequency\")\n",
    "    plt.xlabel(\"Emotion\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No emotions detected during the session.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
